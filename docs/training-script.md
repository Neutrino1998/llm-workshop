# LLM 系统工程培训讲稿

> 预计时长：40-50 分钟
> 目标听众：不熟悉大模型技术的同事
> 核心目标：理解围绕大模型的系统工程在做什么

---

## 开场（2 分钟）

大家好，今天我想和大家聊聊大模型系统工程。

你们可能经常听到 ChatGPT、RAG、Agent 这些词，但这些东西到底是什么？我们工程师围绕大模型在做什么？

今天我不讲理论，我们直接看真实的 API 调用，看数据怎么流动的。我准备了 6 个递进的演示，从最简单的 API 调用开始，一步步加东西，最后你就能理解整个系统是怎么搭起来的。

**【打开演示页面】**

---

## Stage 1：基础调用（5 分钟）

### 概念引入

我们先从最基础的开始。大模型是什么？

**本质上，大模型就是一个 HTTP API。**

没有什么魔法，你发一个 JSON 请求过去，它返回一个 JSON 响应回来。就这么简单。

### 演示

**【输入：什么是机器学习？】**

大家看左边，这是我们发出去的请求体：

```json
{
  "model": "qwen-plus",
  "messages": [{"role": "user", "content": "什么是机器学习？"}]
}
```

就这么几行。`messages` 是一个数组，里面放的是对话内容。

右边是返回的响应，模型生成的回答在 `content` 里，还有一个 `usage` 告诉你消耗了多少 token。

### 关键认知

**记住第一个关键点：大模型是无状态的。**

每次调用都是独立的，它不知道你之前问过什么。你问完这个问题，关掉页面，再来问，它完全不记得你是谁。

那多轮对话是怎么实现的？我们后面会讲。

---

## Stage 2：System Prompt（5 分钟）

### 概念引入

刚才我们只发了一条 user 消息。但实际上，`messages` 数组里可以有不同角色的消息。

其中有一个特殊的角色叫 `system`，它是给模型的"人设设定"。

**同一个问题，不同的 System Prompt，会得到完全不同的回答。**

### 演示

**【输入同样的问题：什么是机器学习？】**

**【点击"老师"预设】**

看，现在请求体变成了两条消息：
- 第一条是 system：「你是一个耐心的老师...」
- 第二条是 user：「什么是机器学习？」

回答用了很多比喻，像在给小朋友讲课。

**【切换到"程序员"预设】**

现在 system 变成了「你是一个资深 Python 开发者...」

回答里直接上代码了，风格完全不一样。

**【可以再演示"创意"预设，会有 emoji 和比喻】**

### 关键认知

**System Prompt 是控制模型行为的核心手段。**

你想让模型扮演客服、扮演翻译、扮演代码助手，都是通过 System Prompt 来实现的。这也是为什么 prompt engineering（提示词工程）这么重要。

---

## Stage 3：多轮对话（5 分钟）

### 概念引入

刚才说大模型是无状态的，那 ChatGPT 那种连续对话是怎么实现的？

答案是：**我们把完整的对话历史手动传给模型。**

模型本身没有记忆，是我们的代码在维护这个记忆。

### 演示

**【第一轮：输入"我叫小明"】**

看右边的 messages 数组，现在有：
- system（如果设了的话）
- user: "我叫小明"
- assistant: "你好小明..."

**【第二轮：输入"我叫什么"】**

现在 messages 变成了：
- user: "我叫小明"
- assistant: "你好小明..."
- user: "我叫什么"  ← 新的
- assistant: "你叫小明"  ← 新的

**看到了吗？每次请求，我们都把之前的对话全部传过去。**

**【继续对话几轮，观察 token 消耗增长】**

注意看 token 消耗，每多一轮，消耗的 token 就越多。因为历史越来越长。

### 关键认知

**多轮对话 = 每次都传完整历史。**

这就是为什么：
1. 对话太长会变慢、变贵
2. 有些产品会限制对话轮数
3. 我们需要做"上下文管理"——决定保留哪些历史、丢弃哪些

---

## Stage 4：工具调用（8 分钟）

### 概念引入

到目前为止，模型只能"说话"。但如果我问它"今天天气怎么样"，它不知道——它的知识是训练时截止的，没有实时信息。

怎么办？让模型能调用工具。

但这里有一个很重要的认知：**模型不会自己执行工具，它只告诉你"我想调什么工具、传什么参数"。**

真正执行工具的是我们的代码。

### 演示

**【输入：帮我搜索一下最新的 AI 新闻】**

**【观察执行轨迹】**

看这个流程：

**① 首次调用**
我们把问题和"可用工具列表"一起发给模型。工具定义包括名称、描述、参数。

**② 模型决策**
模型分析问题后说：「我要调用 web_search，参数是 "AI 新闻"」

注意：到这一步，模型没有搜索任何东西，它只是**告诉我们它想搜**。

**③ 执行工具**
我们的代码看到模型想搜索，就去调用博查搜索 API，拿到真实的搜索结果。

**④ 二次调用**
我们把搜索结果塞回 messages，再调一次模型，模型基于搜索结果生成最终回答。

### 关键认知

**工具调用至少需要两次 API 调用：**
1. 第一次：模型决定用什么工具
2. 第二次：模型基于工具结果生成回答

模型就像一个"指挥官"，它不干活，它只指挥。真正干活的是我们写的代码。

---

## Stage 5：RAG（10 分钟）

### 概念引入

刚才的工具调用解决了"实时信息"的问题。但还有一个问题：**私有知识。**

比如公司内部文档、产品手册、客户数据——这些模型训练时不可能见过。

RAG（检索增强生成）就是解决这个问题的。

**核心思路：先从你的文档里检索相关内容，再让模型基于检索结果回答。**

这个 Stage 我们会看到完整的 RAG 流水线，每一步数据长什么样。

### 演示

#### 步骤 1：加载文档

**【用默认的 URL 抓取一篇文章，或上传一个文档】**

这是原始文档，几千字，模型一次吃不下，也没必要全喂。

#### 步骤 2：切分

**【点击"切分"】**

长文档被切成一个个小块（chunk），每块 300 字左右。

为什么要切？两个原因：
1. 模型有上下文长度限制
2. 我们只想检索相关的部分，不是全部

#### 步骤 3：向量化

**【点击"向量化"】**

每个 chunk 被转成一个向量（一串数字）。

这个向量代表这段文字的"语义"。意思相近的文字，向量也会相近。

**看这个可视化，每个小柱子代表向量的一个维度，有 1000 多维。**

#### 步骤 4：检索

**【输入一个问题，点击"检索"】**

问题也被转成向量，然后计算和所有 chunk 向量的相似度。

返回最相似的 Top 3 结果，还有相似度分数。

**注意：这一步没有调用大模型，只是向量计算。很快，也很便宜。**

#### 步骤 5：生成

**【点击"生成"】**

我们把检索到的 chunk 塞进 prompt：

```
请基于以下参考资料回答用户问题：

【参考资料】
[1] chunk 内容...
[2] chunk 内容...

【用户问题】
xxx
```

然后调用模型生成回答。

### 关键认知

**RAG = 检索 + 生成，分两步走。**

1. 检索：从你的文档里找相关内容（向量搜索，不用大模型）
2. 生成：把检索结果喂给大模型，让它基于这些内容回答

这样模型就能回答关于你私有文档的问题了，而且回答有据可查。

---

## Stage 6：Agentic RAG（10 分钟）

### 概念引入

刚才的 RAG 是一个固定流水线：检索 → 生成，走完就结束。

但现实问题往往更复杂：
- 检索结果不够怎么办？
- 需要搜索互联网补充信息怎么办？
- 需要换个关键词再搜怎么办？

**Agentic RAG 的核心区别：让 Agent 自己决定下一步做什么。**

这就是 ReAct 模式：Reason（思考）→ Act（行动）→ Observe（观察）→ 循环，直到信息足够。

### 演示

**【输入：OpenAI 最新发布了什么模型？和之前的模型相比有什么改进？】**

**【点击"运行 Agent"，观察执行轨迹】**

看这个过程：

**⚙️ 初始化**
Agent 知道自己有哪些工具可用。

**🧠 [轮次 1] 思考**
Agent 分析问题：「需要搜索 OpenAI 最新模型的信息...」
决策：调用 web_search

**🔧 调用工具**
执行搜索。

**👁️ 观察结果**
Agent 看到搜索结果。

**🧠 [轮次 2] 再次思考**
「已经知道最新模型是什么了，但还需要对比信息...」
决策：再搜一次，换个关键词。

**【如果 Agent 认为信息足够，会直接输出答案】**

### 关键认知

**普通 RAG vs Agentic RAG：**

| 普通 RAG | Agentic RAG |
|---------|-------------|
| 固定流水线 | 动态决策循环 |
| 检索一次就生成 | 可能检索多次 |
| 不会判断信息够不够 | Agent 自己评估 |
| 工具固定 | Agent 选择工具 |

Agent 更像一个"有思考能力的助手"，而不是一个"流水线工人"。

---

## 总结（3 分钟）

我们从最简单的 API 调用开始，一步步搭建起来：

```
Stage 1: 基础调用      → LLM 就是个 HTTP API
    ↓
Stage 2: System Prompt → 用人设控制模型行为
    ↓
Stage 3: 多轮对话      → 手动传历史实现"记忆"
    ↓
Stage 4: 工具调用      → 模型指挥，代码执行
    ↓
Stage 5: RAG          → 检索私有知识 + 生成
    ↓
Stage 6: Agentic RAG  → Agent 自主决策循环
```

**核心认知：**

1. **大模型是无状态的** —— 所有"记忆"都是我们维护的
2. **大模型只做决策，不做执行** —— 工具调用、搜索都是我们的代码在做
3. **系统工程 = 围绕模型搭管道** —— prompt 组装、上下文管理、检索、工具编排

现在大家看到 ChatGPT、Copilot、各种 AI 助手，应该能想象背后大概是怎么实现的了。

有什么问题吗？

---

## Q&A 预备问题

1. **Token 是什么？怎么计费？**
   - Token ≈ 词或词片段，中文大约 1 字 = 1-2 token
   - 按输入 + 输出 token 数计费

2. **向量是什么？为什么能表示语义？**
   - 向量是一串数字，通过 Embedding 模型生成
   - 训练过程让语义相近的文本向量相近

3. **RAG 和微调（Fine-tuning）有什么区别？**
   - RAG：检索外部知识，模型本身不变
   - 微调：改变模型参数，让模型"学会"新知识
   - RAG 更灵活、成本更低，适合大部分场景

4. **实际项目中还有什么要考虑？**
   - 向量数据库（Milvus、Pinecone）代替内存存储
   - 更好的切分策略（按语义而非字数）
   - 对话历史压缩、缓存优化
   - 安全性：prompt 注入防护
