# LLM 系统工程培训讲稿


## 开场（3 分钟）

大家好，今天聊大模型系统工程。

你们经常听到 ChatGPT、RAG、Agent 这些词。但有一个问题：大部分介绍都是在讲"这个东西能做什么"，很少有人说清楚"它到底是怎么运作的"。今天我想换个角度——我先告诉你们一个核心原理，然后用 6 个递进的演示来证明：所有看起来很复杂的技术，本质上都在做同一件事。

看完之后，你们再看到任何大模型产品，应该都能猜到背后大概是怎么实现的。

## 核心原理（3 分钟）

在进入演示之前，我要先讲今天最重要的一个认知。理解了这一点，后面所有东西都是它的推论。

**大模型的本质就是文字补全。**给它一段文字，它预测下一个字，然后把预测出来的字加到末尾，再预测下一个字，如此循环。就像手机键盘的自动补全——只不过它的补全能力远远超过手机输入法。你给它"中国的首都是"，它大概率会补出"北京"；你给它一段英文加"翻译成中文"，它会补出中文翻译。它不"理解"什么，不"思考"什么——它只是在做统计意义上最合理的文字补全。只不过当模型足够大时，这种补全涌现出了令人惊讶的智能行为。

那我们工程师在做什么？我们做的所有事情，都可以归纳为一个词：**Context Engineering，上下文工程。**Context 就是塞给模型的那段输入文本。模型只看得到这段文本，Context 里有什么它就知道什么，没有的就不知道。想让它扮演客服？在 Context 里写"你是客服"。想让它有记忆？把对话历史塞进去。想让它回答公司内部文档的问题？把相关文档片段塞进去。我们从来没有改变模型本身，我们只是在构造更好的 Context。

接下来 6 个演示，每一个都是一种 Context Engineering 技术。

**【打开演示页面】**

---

## Stage 1：基础调用 —— 最简单的 Context（5 分钟）

大模型对外暴露的形式就是一个 HTTP API。你发一个 JSON 请求，它返回一个 JSON 响应。核心参数只有一个：messages 数组——这就是我们说的 Context。

**【演示：输入"什么是机器学习？"并发送】**

大家看，messages 数组里只有一条用户消息。模型拿到这段文字，开始补全——它看到这是一个问题，统计意义上最合理的补全就是给出回答。响应里有两个重要信息：content 是模型补全出来的文字，usage 是消耗了多少 token。中文大约 1 个字消耗 1.5 个 token。

这里要记住一句话：大模型是无状态的。每次调用都是独立的，它不记得上一次你问了什么。没有 Context 就没有记忆——这不是 bug，这是本质。

接下来我们看看，在 Context 前面加一段"人设指令"会怎样。

## Stage 2：System Prompt —— 在 Context 里加"人设"（5 分钟）

messages 数组里的消息有三种角色：system 是系统指令，告诉模型"你是谁、该怎么表现"；user 是用户输入；assistant 是模型的回复。System Prompt 就是放在 Context 最前面的一段指令文本，模型开始补全之前先读到它，后续所有输出都会受它影响。同一个问题加不同的 System Prompt，会得到完全不同的回答。

**【演示：同一问题切换不同预设，观察输出变化】**

大家看，选"老师"预设，回答用了很多比喻和类比；切到"程序员"预设，回答里直接上代码了；再切到"创意"预设，画风又完全变了。同一个模型，同一个问题——我们只是在 Context 开头加了一段不同的文字，输出就完全不同。

所以 prompt engineering 的核心就是：你写的 System Prompt 越精确，模型的输出就越符合预期。不是改模型，是改 Context。

人设有了，但模型还是不记得上一轮说了什么。怎么实现连续对话？

## Stage 3：多轮对话 —— 在 Context 里塞历史（5 分钟）

模型没有记忆，那 ChatGPT 那种连续对话怎么实现的？答案很直接：每次调用时，把之前所有的对话历史都塞进 Context。模型不是"记得"之前说过什么，是我们的代码把历史全部重新传给它，让它"看到"之前说过什么。

**【演示：多轮对话，观察 messages 数组增长和 token 消耗】**

大家看，第一轮我输入"我叫小明"，messages 里有 system 加 user 加 assistant 三条消息。第二轮问"我叫什么"，messages 变成了五条——整个对话历史都在 Context 里，模型读到"我叫小明"自然能回答。继续聊几轮，token 消耗一直在涨，因为每次都带着完整历史。现在我点"清空"再问"我叫什么"——模型答不上来了，因为 Context 里没有这个信息了。

所以记住：多轮对话不等于模型记住了，多轮对话等于我们每次把历史全部传进去。对话越长 Context 越大，成本越高——这就是为什么实际工程中要做上下文管理。

到目前为止，模型只能"说"。下一步，我们让它能"做"——调用外部工具。

## Stage 4：工具调用 —— 在 Context 里加"能力描述"（8 分钟）

模型的知识截止在训练时间点，它无法获取实时信息，也不能查数据库、发邮件。工具调用的原理是这样的：我们在 Context 里描述"你有哪些工具可以用"，模型如果认为需要使用某个工具，就补全出一段 JSON 告诉我们它想调什么工具、传什么参数。然后我们的代码真正去执行，把结果塞回 Context，模型再基于结果补全最终回答。

关键在于：模型不执行工具，它只是补全出了"我想调这个工具"的文字。真正执行的是我们的代码。

**【演示：输入搜索请求，观察四步执行轨迹】**

看整个过程——首次调用时，Context 里除了用户消息，还加了工具定义，告诉模型"你有 web_search 和 fetch_url 两个工具可以用"。模型的补全结果不是普通文字，而是一个 tool_calls 结构，说明它想调哪个工具、传什么参数。后端拿到这个结构，去调用真正的搜索 API 拿到结果，然后把搜索结果塞回 messages 再调一次模型。模型看到搜索结果，就能基于真实数据补全最终回答了。

整个过程至少两次 API 调用，每次都是"构造 Context、模型补全"这个循环。模型全程只在做补全，是我们的代码在编排整个流程。

工具调用解决了实时信息的问题。但还有一类问题：公司内部的私有知识怎么办？

## Stage 5：RAG —— 在 Context 里注入私有知识（10 分钟）

公司内部文档、产品手册、客户数据——这些模型训练时不可能见过。但我们又不能把整个文档库都塞进 Context，太长了而且大部分和当前问题无关。RAG，也就是检索增强生成，做法是：先找到和问题相关的文档片段，只把相关片段塞进 Context。接下来每一步的中间数据都可以在界面上看到。

第一步是加载文档。先拿到原始文档，可能有几千上万字。

**【演示：从 URL 抓取文章或上传文档】**

第二步是切分。把长文档切成小块，默认 1000 字带 200 字重叠。检索的粒度是 chunk 而不是整篇文档，这样只把相关的 chunk 塞进 Context，不浪费 token。

**【演示：切分文档，调整参数观察效果】**

第三步是向量化。每个 chunk 被 Embedding 模型转成一个高维向量，就是一串浮点数。核心原理是语义相近的文字在向量空间中距离相近——"用户登录验证"和"身份认证"虽然字面完全不同，向量却会很接近。大家看界面上的可视化，每根小柱子是向量的一个维度，不同 chunk 的图案长得不一样，这就是它们的语义指纹。

**【演示：向量化，观察向量可视化】**

第四步是检索。用户的问题也被转成向量，然后和每个 chunk 向量计算相似度，按分数排序返回最相关的几个。注意，这一步完全没有调用大模型，只是向量数学计算，非常快也非常便宜。

**【演示：输入问题并检索，观察相似度分数】**

最后是组装和生成。把检索到的 chunk 和用户问题组装成完整的 Prompt，大意就是"请基于以下参考资料回答用户问题"，然后把参考资料和问题一起塞进 Context。模型读到这些内容，就能基于私有知识来回答了。

**【演示：生成回答，观察组装后的完整 Prompt】**

所以 RAG 的本质就是用检索来构造更好的 Context。检索阶段不用大模型，生成阶段才用大模型。模型本身没变，我们只是给了它更好的 Context。

刚才的 RAG 是一条固定流水线，走一次就结束。如果检索结果不够好怎么办？接下来看 Agent 怎么动态解决这个问题。

## Stage 6：Agentic RAG —— 动态构造 Context 的循环（8 分钟）

普通 RAG 是"检索、生成"走一次就结束，但现实问题往往需要多步推理：检索结果不够就换个关键词再搜，需要实时信息就调搜索引擎，需要交叉验证就抓取原文确认。Agentic RAG 的核心区别是：Agent 在一个循环中动态决定"下一步往 Context 里加什么信息"。每一轮是"想一想信息够不够、用什么工具获取新信息、新信息加入 Context"，然后重复，直到信息充分为止。

**【演示：运行 Agent，观察多步推理和工具调用过程】**

大家看执行轨迹——注意 Agent 每次运行的路径可能不同。它可能先搜北京再搜东京，也可能反过来，甚至中途决定抓取某个网页获取详细数据。关键不是它走了哪条路，而是它在每一步都在自主判断"Context 里还缺什么信息"，然后选择工具去补齐。

普通 RAG 和 Agentic RAG 的区别：普通 RAG 是一次性构造 Context，固定流程，单一信息来源，适合简单问答；Agentic RAG 是多轮迭代构造 Context，Agent 自主决策，可以用多种工具，适合复杂分析和多步推理。

好，6 个阶段全部看完了。

---

## 总结：一个模型，一种工程（3 分钟）

回顾一下这 6 个阶段，它们看起来差别很大，但用 Context Engineering 的视角看，都在做同一件事——往 Context 里加不同的东西。Stage 1 只有用户输入；Stage 2 加了人设指令；Stage 3 加了完整对话历史；Stage 4 加了工具定义和工具执行结果；Stage 5 加了检索到的文档片段；Stage 6 则是动态构造，循环丰富，直到信息充分。

模型始终只做一件事：基于 Context 补全文字。我们始终只做一件事：构造更好的 Context。

所以今天希望大家带走三个核心认知。第一，大模型本质上是文字补全机，它不思考，它做统计意义上最合理的补全，但当模型足够大时，这种补全涌现出了类似思考的效果。第二，Context 是模型唯一的信息来源，Context 里没有的信息，模型就是不知道，无论这个信息多么重要。第三，我们做的所有系统工程，本质都是 Context Engineering——prompt engineering、多轮对话管理、工具编排、RAG、Agent，核心目标只有一个：在有限的 context window 里，塞进对当前任务最有价值的信息。

最后一句话总结：大模型的能力上限由模型决定，但实际表现由 Context 决定。我们的工作就是构造更好的 Context。

有什么问题吗？

---

## Q&A 预备（备用，按需展开）

- **Token 是什么？** 模型处理文本的基本单位，中文约 1 字 ≈ 1-2 token，按输入+输出计费，Context 越长成本越高。
- **向量为什么能表示语义？** Embedding 模型训练时学会把意思相近的文字映射到空间中相近的位置，所以可以按意思搜索。
- **RAG 和微调有什么区别？** RAG 是开卷考试，给模型参考资料，模型不变；微调是闭卷考试，改变模型参数，成本高。
- **Context window 限制怎么处理？** 只保留最近 N 轮对话、RAG 只取 Top 几个高质量 chunk、核心是在有限窗口里塞最有价值的信息。
- **ChatGPT 的"记忆"是怎么回事？** 本质也是 Context Engineering——提取偏好存入记忆库，下次对话时注入 System Prompt，原理和 RAG 一样。